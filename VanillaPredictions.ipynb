{
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oerFICwjHR_R",
        "01D4LrK4MM2Y"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1 - Implementing a Seq2Seq model without Attention"
      ],
      "metadata": {
        "id": "wWLeSd5DeTJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Necessary Libraries"
      ],
      "metadata": {
        "id": "YBG6O3-EalNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "def print_keys_for_values(dictionary, values):\n",
        "    found_keys = []\n",
        "    for value in values:\n",
        "        for key, val in dictionary.items():\n",
        "            if value == val:\n",
        "                found_keys.append(key)\n",
        "    if found_keys:\n",
        "        str = ''.join(found_keys)\n",
        "        if(str[-1] == '\\n'):\n",
        "          str = str[:-1]\n",
        "        elif(str[0] == '\\t'):\n",
        "          str = str[1:]\n",
        "    else:\n",
        "        print(\"No keys found for the given values.\")\n",
        "\n",
        "    return str\n",
        "\n",
        "\n",
        "#Outputs = [32,68,22]\n",
        "#Targets = [32,22]\n",
        "\n",
        "def char_level_accuracy(targets, outputs):\n",
        "    \n",
        "  with torch.no_grad():\n",
        "    count = 0\n",
        "    total_count = 0\n",
        "#     outputs = torch.argmax(outputs, dim = 1)\n",
        "    for i in range(targets.shape[0]):\n",
        "        same_elements = []\n",
        "        for j in range(targets.shape[1]):\n",
        "            if(targets[i][j] != 67 or targets[i][j] != 66):\n",
        "                same_elements.append(outputs[i][j].item() == targets[i][j].item())\n",
        "        count += np.sum(same_elements)\n",
        "        total_count += len(same_elements)\n",
        "  return count/(total_count)\n",
        "\n",
        "\n",
        "\n",
        "def word_level_accuracy(targets, outputs):\n",
        "  outputs1 = torch.argmax(outputs, dim = 1)\n",
        "  with torch.no_grad():\n",
        "    count = 0\n",
        "    for i in range(targets.shape[0]):\n",
        "      if ((outputs1[i] == targets[i]).sum().item() == targets.shape[1]):\n",
        "        count = count + 1\n",
        "  return count/targets.shape[0]\n",
        "\n",
        "def sample_equidistant_points(data, epochs):\n",
        "    step = len(data) // epochs\n",
        "    indices = np.arange(0, len(data), step)\n",
        "    equidistant_points = [data[i] for i in indices]\n",
        "    \n",
        "    return equidistant_points\n",
        "  \n",
        "# A = torch.tensor(np.array([[1,2,3,6],[1,2,3,7]]))\n",
        "# B = torch.tensor(np.array([[1,2,6,6],[1,1,6,6]]))\n",
        "# print(A)\n",
        "# print(B)\n",
        "# print(char_level_accuracy(A,B))\n"
      ],
      "metadata": {
        "id": "V7D3_omDAZ5z",
        "execution": {
          "iopub.status.busy": "2023-05-20T19:14:44.706748Z",
          "iopub.execute_input": "2023-05-20T19:14:44.707462Z",
          "iopub.status.idle": "2023-05-20T19:14:45.984285Z",
          "shell.execute_reply.started": "2023-05-20T19:14:44.707422Z",
          "shell.execute_reply": "2023-05-20T19:14:45.983169Z"
        },
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU\n",
        "import wandb\n",
        "# print(wandb.util.generate_id())\n",
        "# wandb sync --id= wandb.util.generate_id()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-20T19:14:45.988437Z",
          "iopub.execute_input": "2023-05-20T19:14:45.990551Z",
          "iopub.status.idle": "2023-05-20T19:15:03.797552Z",
          "shell.execute_reply.started": "2023-05-20T19:14:45.990505Z",
          "shell.execute_reply": "2023-05-20T19:15:03.796387Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTzR51dhdvCx",
        "outputId": "58f075eb-b0ed-4423-e812-a1fcd51a1239"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-20T19:15:03.799190Z",
          "iopub.execute_input": "2023-05-20T19:15:03.799572Z",
          "iopub.status.idle": "2023-05-20T19:15:46.162760Z",
          "shell.execute_reply.started": "2023-05-20T19:15:03.799525Z",
          "shell.execute_reply": "2023-05-20T19:15:46.161690Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "ewFP7TJ9dvCy",
        "outputId": "8eb0ef8c-c959-44d3-e311-edb5ae795733"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "OSpaGMeKaMEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the data"
      ],
      "metadata": {
        "id": "UhBSddg5dUDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = open('/content/drive/MyDrive/aksharantar_sampled/mar/mar_test.csv')\n",
        "file2 = open('/content/drive/MyDrive/aksharantar_sampled/mar/mar_valid.csv')\n",
        "file3 = open('/content/drive/MyDrive/aksharantar_sampled/mar/mar_train.csv')\n",
        "\n",
        "csvreader1 = csv.reader(file1)\n",
        "csvreader2 = csv.reader(file2)\n",
        "csvreader3 = csv.reader(file3)\n",
        "\n",
        "\n",
        "header1 = []\n",
        "header1 = next(csvreader1)\n",
        "\n",
        "header2 = []\n",
        "header2 = next(csvreader2)\n",
        "\n",
        "header3 = []\n",
        "header3 = next(csvreader3)\n",
        "\n",
        "test = []\n",
        "val = []\n",
        "train = []\n",
        "for row in csvreader1:\n",
        "        test.append(row)\n",
        "\n",
        "for row in csvreader2:\n",
        "        val.append(row)\n",
        "\n",
        "for row in csvreader3:\n",
        "        train.append(row)\n",
        "\n",
        "\n",
        "file1.close()\n",
        "file2.close()\n",
        "file3.close()"
      ],
      "metadata": {
        "id": "GpjDc5UgaSaB",
        "execution": {
          "iopub.status.busy": "2023-05-20T19:15:46.169460Z",
          "iopub.execute_input": "2023-05-20T19:15:46.172347Z",
          "iopub.status.idle": "2023-05-20T19:15:46.574800Z",
          "shell.execute_reply.started": "2023-05-20T19:15:46.172294Z",
          "shell.execute_reply": "2023-05-20T19:15:46.573559Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Processing"
      ],
      "metadata": {
        "id": "WGf_iGuYg0A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(list):\n",
        "  inputs = []\n",
        "  targets = []\n",
        "  for pair in list:\n",
        "    inputs.append(pair[0])\n",
        "    targets.append(pair[1])\n",
        "  return inputs,targets\n",
        "\n",
        "train_inputs, train_targets = read_data(train)\n",
        "test_inputs, test_targets = read_data(test)\n",
        "val_inputs, val_targets = read_data(val)\n",
        "\n",
        "print(train_inputs[1])\n",
        "print(train_targets[1])"
      ],
      "metadata": {
        "id": "WsDuRGn5diPT",
        "execution": {
          "iopub.status.busy": "2023-05-20T19:15:46.580092Z",
          "iopub.execute_input": "2023-05-20T19:15:46.582809Z",
          "iopub.status.idle": "2023-05-20T19:15:46.622083Z",
          "shell.execute_reply.started": "2023-05-20T19:15:46.582766Z",
          "shell.execute_reply": "2023-05-20T19:15:46.621122Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4798ff4d-968a-4d96-ea92-9ec6a1389375"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vhayaki\n",
            "व्हायकी\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_char = '\\t'\n",
        "end_char = '\\n'\n",
        "blank_char = ' '\n",
        "unknown_char = '\\r'"
      ],
      "metadata": {
        "id": "DS5XcLIToSUz",
        "execution": {
          "iopub.status.busy": "2023-05-20T19:15:46.626633Z",
          "iopub.execute_input": "2023-05-20T19:15:46.629389Z",
          "iopub.status.idle": "2023-05-20T19:15:46.637690Z",
          "shell.execute_reply.started": "2023-05-20T19:15:46.629348Z",
          "shell.execute_reply": "2023-05-20T19:15:46.636409Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def language_dict(inputs,targets):\n",
        "  input_dict = {}\n",
        "  max_input_length = 0\n",
        "  input_char = []\n",
        "\n",
        "  target_dict = {}\n",
        "  max_target_length = 0\n",
        "  target_char = []\n",
        "  #Encoding Inputs and updating input_dict\n",
        "  for string in inputs:\n",
        "    max_input_length = max(len(string), max_input_length)\n",
        "    for char in string:\n",
        "      if char not in input_dict:\n",
        "        input_dict[char] = len(input_char)\n",
        "        input_char.append(char)\n",
        "  if blank_char not in input_dict:\n",
        "    input_dict[blank_char] = len(input_char)\n",
        "    input_char.append(blank_char)\n",
        "    \n",
        "  input_dict[unknown_char] = len(input_char)\n",
        "  input_char.append(unknown_char)\n",
        "  \n",
        "  if start_char not in target_dict:\n",
        "    target_dict[start_char] = len(target_char)\n",
        "    target_char.append(start_char)\n",
        "\n",
        "  for string in targets:\n",
        "    max_target_length = max(len(string)+2, max_target_length)\n",
        "    for char in string:\n",
        "      if char not in target_dict:\n",
        "        target_dict[char] = len(target_char)\n",
        "        target_char.append(char)\n",
        "\n",
        "  if end_char not in target_dict:\n",
        "    target_dict[end_char] = len(target_char)\n",
        "    target_char.append(end_char)\n",
        "\n",
        "  if blank_char not in target_dict:\n",
        "    target_dict[blank_char] = len(target_char)\n",
        "    target_char.append(blank_char)\n",
        "    \n",
        "  return input_dict,max_input_length,input_char,target_dict ,max_target_length,target_char\n",
        "\n",
        "# input_dict,max_input_length,input_char,target_dict ,max_target_length,target_char = language_dict(test_inputs,test_targets)     \n",
        "input_dict,max_input_length,input_char,target_dict,max_target_length,target_char = language_dict(train_inputs+val_inputs+test_inputs,train_targets+val_targets+test_targets)     \n",
        "\n",
        "def word_to_encoding(word_list, language_dict, max_length, language):\n",
        "    encodings = []\n",
        "    for word in word_list:\n",
        "        encoding = []\n",
        "        for char in word:\n",
        "            if char in language_dict:\n",
        "                encoding.append(language_dict[char])\n",
        "            else:\n",
        "                encoding.append(language_dict[unknown_char])\n",
        "        if (language == 0):\n",
        "          while len(encoding) < max_length:\n",
        "              encoding.append(language_dict[blank_char])\n",
        "        if (language == 1):\n",
        "          encoding.insert(0,language_dict[start_char])\n",
        "          while len(encoding) < max_length-1:\n",
        "            encoding.append(language_dict[blank_char])\n",
        "          encoding.append(language_dict[end_char])\n",
        "        encodings.append(encoding)\n",
        "    return encodings\n",
        "\n",
        "\n",
        "  \n",
        "def process_data(train,val,test,input_dict,target_dict,max_input_length,max_target_length):\n",
        "\n",
        "  train_inputs, train_targets = read_data(train)\n",
        "  test_inputs, test_targets = read_data(test)\n",
        "  val_inputs, val_targets = read_data(val)\n",
        "\n",
        "  encoded_train_inputs = word_to_encoding(train_inputs,input_dict,max_input_length,0)\n",
        "  encoded_train_targets = word_to_encoding(train_targets,target_dict,max_target_length,1)\n",
        "  encoded_val_inputs = word_to_encoding(val_inputs,input_dict,max_input_length,0)\n",
        "  encoded_val_targets = word_to_encoding(val_targets,target_dict,max_target_length,1)\n",
        "  encoded_test_inputs = word_to_encoding(test_inputs,input_dict,max_input_length,0)\n",
        "  encoded_test_targets = word_to_encoding(test_targets,target_dict,max_target_length,1)\n",
        "\n",
        "  return encoded_train_inputs,encoded_train_targets, encoded_val_inputs, encoded_val_targets, encoded_test_inputs, encoded_test_targets\n",
        "\n",
        "\n",
        "encoded_train_inputs,encoded_train_targets,encoded_val_inputs, encoded_val_targets, encoded_test_inputs, encoded_test_targets = process_data(train,val,test,input_dict,target_dict,max_input_length,max_target_length)\n",
        "\n",
        "\n",
        "r = random.randint(0,100)\n",
        "print(print_keys_for_values(input_dict,encoded_train_inputs[int(r)]))\n",
        "print(print_keys_for_values(target_dict,encoded_train_targets[int(r)]))\n"
      ],
      "metadata": {
        "id": "Z4gsiss3mRp9",
        "execution": {
          "iopub.status.busy": "2023-05-20T19:15:46.642829Z",
          "iopub.execute_input": "2023-05-20T19:15:46.645423Z",
          "iopub.status.idle": "2023-05-20T19:15:48.570640Z",
          "shell.execute_reply.started": "2023-05-20T19:15:46.645383Z",
          "shell.execute_reply": "2023-05-20T19:15:48.569597Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "912d75a5-4184-4683-fcae-5ac3fa855fa6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ulca                        \n",
            "\tयुएलसीए             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_tensor_pairs(train_inputs, train_targets):\n",
        "    pairs = []\n",
        "    for input_data, target_data in zip(train_inputs, train_targets):\n",
        "        input_tensor = torch.tensor(input_data)\n",
        "        target_tensor = torch.tensor(target_data)\n",
        "        pairs.append((input_tensor,target_tensor))\n",
        "    return pairs\n",
        "\n",
        "encoded_train_pairs = convert_to_tensor_pairs(encoded_train_inputs,encoded_train_targets)\n",
        "\n",
        "encoded_val_pairs = convert_to_tensor_pairs(encoded_val_inputs,encoded_val_targets)\n",
        "\n",
        "encoded_test_pairs = convert_to_tensor_pairs(encoded_test_inputs,encoded_test_targets)\n",
        "\n",
        "pairs = (encoded_train_pairs, encoded_val_pairs, encoded_test_pairs)\n",
        "pair = random.choice(encoded_train_pairs)\n",
        "\n",
        "print(print_keys_for_values(input_dict, pair[0]))\n",
        "print(print_keys_for_values(target_dict, pair[1]))\n",
        "\n"
      ],
      "metadata": {
        "id": "OMKH8riwIOlb",
        "execution": {
          "iopub.status.busy": "2023-05-20T19:15:48.577849Z",
          "iopub.execute_input": "2023-05-20T19:15:48.581913Z",
          "iopub.status.idle": "2023-05-20T19:15:50.303070Z",
          "shell.execute_reply.started": "2023-05-20T19:15:48.581834Z",
          "shell.execute_reply": "2023-05-20T19:15:50.302070Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c1b34c-5350-4632-b10f-afed790970e6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "manachevar                  \n",
            "\tमनाचेवर             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seq2Seq Model without Attention"
      ],
      "metadata": {
        "id": "Q8iP5v9WaVdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder"
      ],
      "metadata": {
        "id": "oerFICwjHR_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, device, cell_type, vocab_size, embed_dim, hidden_size, num_layers=1, bidirectional=False, dropout_p=0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.cell_type = cell_type\n",
        "        self.dropout_p = dropout_p\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        if(cell_type == 'lstm'):\n",
        "          self.rnn = nn.LSTM(embed_dim, hidden_size, num_layers = self.num_layers, batch_first=True, dropout = dropout_p, bidirectional=self.bidirectional)\n",
        "        elif (cell_type == 'rnn'):\n",
        "          self.rnn = nn.RNN(embed_dim, hidden_size, num_layers = self.num_layers, batch_first=True,dropout = dropout_p, bidirectional=self.bidirectional)\n",
        "        elif (cell_type == 'gru'):\n",
        "          self.rnn = nn.GRU(embed_dim, hidden_size, num_layers = self.num_layers, batch_first=True,dropout = dropout_p, bidirectional=self.bidirectional)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        out = self.embedding(x)#.unsqueeze(1)\n",
        "        out = self.dropout(out)\n",
        "        if (self.cell_type == 'lstm'):\n",
        "          out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
        "          return out, hidden, cell\n",
        "        elif (self.cell_type == 'rnn'):\n",
        "          out, hidden = self.rnn(out, hidden)\n",
        "          return out, hidden\n",
        "        elif (self.cell_type == 'gru'):\n",
        "          out, hidden = self.rnn(out,hidden) \n",
        "          return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.randn((1+int(self.bidirectional))*self.num_layers, batch_size, self.hidden_size, device=device)\n",
        "        cell = torch.randn((1+int(self.bidirectional))*self.num_layers, batch_size, self.hidden_size, device=device)\n",
        "        return hidden, cell\n"
      ],
      "metadata": {
        "id": "UBE07BLxae-0",
        "execution": {
          "iopub.status.busy": "2023-05-20T19:15:50.307853Z",
          "iopub.execute_input": "2023-05-20T19:15:50.310419Z",
          "iopub.status.idle": "2023-05-20T19:15:50.331613Z",
          "shell.execute_reply.started": "2023-05-20T19:15:50.310377Z",
          "shell.execute_reply": "2023-05-20T19:15:50.330494Z"
        },
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder"
      ],
      "metadata": {
        "id": "01D4LrK4MM2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, device, cell_type, output_vocab, embed_size, hidden_size, max_length, dropout_p=0.1, num_layers = 1, bidirectional = False):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_vocab\n",
        "        self.embed_size = embed_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.cell_type = cell_type \n",
        "        self.max_length = max_length\n",
        "        self.device = device\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding_decoder = nn.Embedding(self.output_size, self.embed_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "\n",
        "        if (cell_type == 'lstm'):\n",
        "          self.rnn = nn.LSTM( self.embed_size, hidden_size, num_layers = self.num_layers, batch_first=True, bidirectional=self.bidirectional, dropout = self.dropout_p)\n",
        "        elif (cell_type == 'gru'):\n",
        "          self.rnn = nn.GRU( self.embed_size, hidden_size, num_layers = self.num_layers, batch_first=True, bidirectional=self.bidirectional, dropout = self.dropout_p)\n",
        "        elif (cell_type == 'rnn'):\n",
        "          self.rnn = nn.RNN( self.embed_size, hidden_size, num_layers = self.num_layers, batch_first=True, bidirectional=self.bidirectional, dropout = self.dropout_p)\n",
        "\n",
        "        self.out = nn.Linear((1+int(self.bidirectional))*self.hidden_size, self.output_size)\n",
        "        self.out_activation = nn.LogSoftmax(dim=-1)\n",
        "  \n",
        "\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        input = input.unsqueeze(1)\n",
        "        embedded_decoder = self.embedding_decoder(input)\n",
        "        embedded_decoder = self.dropout(embedded_decoder)\n",
        "\n",
        "\n",
        "        if (self.cell_type == 'lstm'):\n",
        "          output, (hidden, cell) = self.rnn(embedded_decoder, (hidden, cell))\n",
        "        elif (self.cell_type == 'gru'):\n",
        "          output, hidden = self.rnn(embedded_decoder, hidden)\n",
        "        elif (self.cell_type == 'rnn'):\n",
        "          output,hidden = self.rnn(embedded_decoder, hidden)\n",
        "    \n",
        "        output = F.relu(self.out(output))\n",
        "        output = F.log_softmax(output,dim=-1)\n",
        "\n",
        "        return output, hidden, cell\n",
        "\n",
        "    def init_hidden(self, encoder_hidden, encoder_cell, encoder_bidirectional):\n",
        "        hidden = encoder_hidden[-(1+int(encoder_bidirectional)): ].repeat(self.num_layers,1,1)\n",
        "        cell = encoder_cell[-(1+int(encoder_bidirectional)): ].repeat(self.num_layers,1,1)\n",
        "        return hidden, cell"
      ],
      "metadata": {
        "id": "UnPfGfWSKihu",
        "execution": {
          "iopub.status.busy": "2023-05-20T19:15:50.338594Z",
          "iopub.execute_input": "2023-05-20T19:15:50.341128Z",
          "iopub.status.idle": "2023-05-20T19:15:50.366372Z",
          "shell.execute_reply.started": "2023-05-20T19:15:50.341073Z",
          "shell.execute_reply": "2023-05-20T19:15:50.365233Z"
        },
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Seq2Seq Model"
      ],
      "metadata": {
        "id": "-l-JHa_k_3Ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        self.max_target_length = 0\n",
        "        self.sos = 0\n",
        "        \n",
        "        \n",
        "    def forward(self, source, target, teacher_forcing_ratio = 0.5):\n",
        "      \n",
        "        batch_size = target.shape[0]\n",
        "        target_len = target.shape[1]\n",
        "        self.max_target_length = target_len\n",
        "        target_vocab_size = self.decoder.output_size\n",
        "        \n",
        "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_hidden, encoder_cell = self.encoder.init_hidden(batch_size)\n",
        "\n",
        "        \n",
        "        if (self.encoder.cell_type == 'lstm'):\n",
        "          encoder_outputs, encoder_hidden, encoder_cell = self.encoder.forward(source, encoder_hidden, encoder_cell)\n",
        "        if (self.encoder.cell_type == 'rnn'):\n",
        "          encoder_outputs, encoder_hidden = self.encoder.forward(source, encoder_hidden, encoder_cell)\n",
        "        if (self.encoder.cell_type == 'gru'):\n",
        "          encoder_outputs, encoder_hidden = self.encoder.forward(source, encoder_hidden, encoder_cell)\n",
        "\n",
        "\n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = target[:,0]\n",
        "        self.sos = target[:,0]\n",
        "        hidden,cell = self.decoder.init_hidden(encoder_hidden, encoder_cell, self.encoder.bidirectional)\n",
        "        \n",
        "        for t in range(1, target_len):\n",
        "            output, hidden, cell = self.decoder.forward(input, hidden, cell)\n",
        "            outputs[:,t] = output.squeeze(1)\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(-1)\n",
        "            input = target[:,t] if teacher_force else top1.squeeze(1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def inference(self, source, target):\n",
        "      \n",
        "        batch_size = source.shape[0]\n",
        "        target_len = self.max_target_length\n",
        "        target_vocab_size = self.decoder.output_size\n",
        "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(self.device)\n",
        "        encoder_hidden, encoder_cell = self.encoder.init_hidden(batch_size)\n",
        "\n",
        "        \n",
        "        if (self.encoder.cell_type == 'lstm'):\n",
        "          encoder_outputs, encoder_hidden, encoder_cell = self.encoder.forward(source, encoder_hidden, encoder_cell)\n",
        "        if (self.encoder.cell_type == 'rnn'):\n",
        "          encoder_outputs, encoder_hidden = self.encoder.forward(source, encoder_hidden, encoder_cell)\n",
        "        if (self.encoder.cell_type == 'gru'):\n",
        "          encoder_outputs, encoder_hidden = self.encoder.forward(source, encoder_hidden, encoder_cell)\n",
        "           \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = self.sos\n",
        "\n",
        "        hidden,cell = self.decoder.init_hidden(encoder_hidden, encoder_cell, self.encoder.bidirectional)\n",
        "      \n",
        "        \n",
        "        for t in range(1, target_len):\n",
        "            output, hidden, cell = self.decoder.forward(input, hidden, cell)\n",
        "            outputs[:,t] = output.squeeze(1)\n",
        "            top1 = output.argmax(-1)\n",
        "            input = top1.squeeze(1)\n",
        "\n",
        "        # print(f\"Outputs = {outputs[:,0]}\")\n",
        "        # print(f\"Targets = {target[:,0]}\")\n",
        "        \n",
        "        return outputs"
      ],
      "metadata": {
        "id": "z0hxKAS8_2wQ",
        "execution": {
          "iopub.status.busy": "2023-05-20T19:15:50.372930Z",
          "iopub.execute_input": "2023-05-20T19:15:50.375780Z",
          "iopub.status.idle": "2023-05-20T19:15:50.404418Z",
          "shell.execute_reply.started": "2023-05-20T19:15:50.375739Z",
          "shell.execute_reply": "2023-05-20T19:15:50.403352Z"
        },
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the Seq2Seq Model"
      ],
      "metadata": {
        "id": "ZUxIF8m1L3gM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = len(input_dict)\n",
        "output_dim = len(target_dict)\n",
        "batch_size = 32\n",
        "val_batch_size = 32\n",
        "enc_embedding = 256\n",
        "dec_embedding = 256\n",
        "hidden = 512\n",
        "enc_num_layers = 3\n",
        "dec_num_layers = 2\n",
        "enc_dropout = 0.4\n",
        "dec_dropout = 0.4\n",
        "max_length = max_target_length\n",
        "cell_type = 'gru'\n",
        "\n",
        "\n",
        "    \n",
        "enc = EncoderRNN(device, cell_type, input_dim, enc_embedding, hidden, enc_num_layers, bidirectional = True, dropout_p = enc_dropout)\n",
        "dec = DecoderRNN(device, cell_type, output_dim, dec_embedding, hidden, max_length,  dec_dropout, dec_num_layers , bidirectional = True)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "def trainIters(model, pairs, batch_size, n_iters, optimizer, tf, print_every=10, plot_every=10, log = True, Attention = False):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    train_char_accuracy = []\n",
        "    train_word_accuracy = []\n",
        "    val_losses = []\n",
        "    val_char_accuracy = []\n",
        "    val_word_accuracy = []\n",
        "    print_loss_total = 0  \n",
        "    plot_loss_total = 0  \n",
        "    print_val_loss_total = 0\n",
        "    plot_val_loss_total = 0 \n",
        "\n",
        "    train_pairs = pairs[0]\n",
        "    val_pairs = pairs[1]\n",
        "    train_accuracy = 0\n",
        "    \n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    count = 0\n",
        "    for iter in range(1,n_iters+1): \n",
        "      for i in np.arange(start=0, stop=len(train_pairs)-batch_size, step=batch_size):\n",
        "        train_accuracy = 0\n",
        "        count += 1\n",
        "        if (i + batch_size > len(train_pairs)):\n",
        "          batch_size = len(train_pairs) - i + 1  \n",
        "        input_tensor = []\n",
        "        target_tensor = []\n",
        "        \n",
        "        for j in range(batch_size):\n",
        "            input_tensor.append(train_pairs[i+j][0])\n",
        "            target_tensor.append(train_pairs[i+j][1]) \n",
        "            \n",
        "        input_tensor = torch.stack(input_tensor).squeeze(1).long().cuda()\n",
        "        target_tensor = torch.stack(target_tensor).squeeze(1).long().cuda()\n",
        "        \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        if (count < 4000):\n",
        "          out = model(input_tensor, target_tensor, teacher_forcing_ratio=tf)\n",
        "        else:\n",
        "          out = model(input_tensor, target_tensor , teacher_forcing_ratio=0)\n",
        "        \n",
        "        out = torch.permute(out,[0,2,1])\n",
        "        # if (count%1000 == 0):\n",
        "        #     print(f'Input Tensor:{print_keys_for_values(input_dict, input_tensor[1])}')\n",
        "        #     print(f'Target Tensor:{print_keys_for_values(target_dict, target_tensor[1])}')\n",
        "        #     print(f'Out Tensor:{print_keys_for_values(target_dict, torch.argmax(out[1], dim = 0))}')\n",
        "        #     print(target_tensor[1])\n",
        "        #     print(torch.argmax(out[1], dim = 0))\n",
        "        loss = criterion(out, target_tensor)\n",
        "\n",
        "#         train_accuracy_char = char_level_accuracy(target_tensor, out)*batch_size*target_tensor[1]\n",
        "        \n",
        "        \n",
        "        train_accuracy_word = word_level_accuracy(target_tensor, out)*batch_size\n",
        "        train_accuracy = train_accuracy + train_accuracy_word\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "        optimizer.step()\n",
        "\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if count % 800 == 0:\n",
        "            val_input_tensor = []\n",
        "            val_target_tensor = []\n",
        "\n",
        "            for j in range(batch_size):\n",
        "                val_input_tensor.append(val_pairs[j][0])\n",
        "                val_target_tensor.append(val_pairs[j][1]) \n",
        "\n",
        "            val_input_tensor = torch.stack(val_input_tensor).squeeze(1).long().cuda()\n",
        "            val_target_tensor = torch.stack(val_target_tensor).squeeze(1).long().cuda()\n",
        "            if (Attention == True):\n",
        "                val_out,_ = model.inference(val_input_tensor, val_target_tensor)\n",
        "                val_out = val_out.permute(0,2,1)\n",
        "            else:\n",
        "                val_out = model.inference(val_input_tensor, val_target_tensor)\n",
        "                val_out = val_out.permute(0,2,1)\n",
        "            val_loss = criterion(val_out, val_target_tensor)\n",
        "            val_loss_sampled = val_loss\n",
        "            wandb.log({'Val_Loss': val_loss_sampled})\n",
        "\n",
        "            \n",
        "        \n",
        "        if count % 800 == 0:\n",
        "            print_loss_avg = print_loss_total / 800\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.7f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "                                      \n",
        "\n",
        "        if count % 800 == 0:\n",
        "            plot_loss_avg = plot_loss_total / 800\n",
        "            # train_char_accuracy.append(train_accuracy_char)\n",
        "            # train_word_accuracy.append(train_accuracy_word)\n",
        "            plot_losses.append(plot_loss_avg.detach())\n",
        "            wandb.log({'Train Loss': plot_loss_avg})\n",
        "\n",
        "            plot_loss_total = 0\n",
        "        \n",
        "      train_accuracy = train_accuracy/(len(train_pairs)-batch_size)\n",
        "      train_word_accuracy.append(train_accuracy)#Need to log this list\n",
        "    \n",
        "    print(train_word_accuracy)\n",
        "    plot_losses = [losses.cpu().numpy() for losses in plot_losses]\n",
        "    plot_losses_sampled = sample_equidistant_points(plot_losses, n_iters)#Need to log this list\n",
        "    \n",
        "    char_count = 0\n",
        "    word_count = 0\n",
        "        \n",
        "    for i in np.arange(start=0, stop=len(val_pairs)-batch_size, step=batch_size):\n",
        "        if (i + batch_size > len(val_pairs)):\n",
        "          batch_size = len(val_pairs) - i + 1  \n",
        "        val_input_tensor = []\n",
        "        val_target_tensor = []\n",
        "        for j in range(batch_size):\n",
        "            val_input_tensor.append(val_pairs[i+j][0])\n",
        "            val_target_tensor.append(val_pairs[i+j][1])\n",
        "\n",
        "        val_input_tensor = torch.stack(val_input_tensor).squeeze(1).long().cuda()\n",
        "        val_target_tensor = torch.stack(val_target_tensor).squeeze(1).long().cuda()\n",
        "        if (Attention == True):\n",
        "            val_out,_ = model.inference(val_input_tensor, val_target_tensor)\n",
        "            val_out = val_out.permute(0,2,1)\n",
        "        else:\n",
        "            val_out = model.inference(val_input_tensor, val_target_tensor)\n",
        "            val_out = val_out.permute(0,2,1)\n",
        "        val_loss = criterion(val_out, val_target_tensor)\n",
        "        \n",
        "        \n",
        "        # print(torch.argmax(val_out, dim = 1))\n",
        "        # print(val_target_tensor)\n",
        "\n",
        "\n",
        "        # val_accuracy_char = char_level_accuracy(val_target_tensor, val_out)\n",
        "        val_accuracy_word = word_level_accuracy(val_target_tensor, val_out)\n",
        "        # char_count = char_count + (val_accuracy_char)*batch_size*val_target_tensor.shape[1]\n",
        "        word_count = word_count + (val_accuracy_word)*batch_size\n",
        "        # print(word_count)\n",
        "    \n",
        "\n",
        "    # char_accuracy = char_count/((len(val_pairs)-batch_size)*(val_target_tensor.shape[1]))\n",
        "    word_accuracy = word_count/(len(val_pairs)-batch_size) #Need to log this value = Val_Word_Accuracy\n",
        "    \n",
        "    metrics = {'Val_Accuracy': word_accuracy}\n",
        "    wandb.log(metrics)\n",
        "    \n",
        "                                \n",
        "    \n",
        "    print(f\"Val loss = {val_loss}\")\n",
        "    # print(f'Character-level-accuracy on val set = {char_accuracy}')\n",
        "    print(f'Word-level-accuracy on val set = {word_accuracy}')\n",
        "    fig, axs = plt.subplots(2, figsize = (30,20))\n",
        "    axs[0].plot(plot_losses_sampled)\n",
        "    axs[0].set_ylabel('Train Loss')\n",
        "    # axs[1].plot(train_char_accuracy)\n",
        "    # axs[1].set_ylabel('Train Accuracy(Char)')\n",
        "    axs[1].plot(train_word_accuracy)\n",
        "    axs[1].set_ylabel('Train Accuracy(Word)')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3_VZGr2LQ4Lk",
        "execution": {
          "iopub.status.busy": "2023-05-20T19:15:50.409635Z",
          "iopub.execute_input": "2023-05-20T19:15:50.412273Z",
          "iopub.status.idle": "2023-05-20T19:15:56.159780Z",
          "shell.execute_reply.started": "2023-05-20T19:15:50.412233Z",
          "shell.execute_reply": "2023-05-20T19:15:56.158697Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce580ff2-3adf-4c99-c890-ed6f840ecea3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 18,998,083 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 - Seq2Seq Model WandB Sweep "
      ],
      "metadata": {
        "id": "Iz_KOyjNefG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'name' : 'Hyperparameter Tuning-Bayesian'\n",
        "}\n",
        "\n",
        "metric = {\n",
        "    'name': 'Val_Accuracy',\n",
        "    'goal': 'maximize'   \n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "\n",
        "parameters_dict = {\n",
        "    'optimiser': {\n",
        "        'values': ['adam']\n",
        "        },\n",
        "    'teacher_forcing_ratio':{\n",
        "         'values':[0.5,0.7]\n",
        "        },\n",
        "    'bidirectional':{\n",
        "         'values':[True]\n",
        "        },\n",
        "    'enc_embedding': {\n",
        "        'values': [128]\n",
        "        },\n",
        "    'dec_embedding': {\n",
        "        'values': [128]\n",
        "        },\n",
        "    'epochs': {\n",
        "          'values': [5,8]\n",
        "        },\n",
        "    'hidden_size': {\n",
        "          'values': [512]\n",
        "        },\n",
        "    'enc_layers': {\n",
        "          'values': [3]\n",
        "        },\n",
        "    'dec_layers': {\n",
        "          'values': [3]\n",
        "        },\n",
        "    'dropout': {\n",
        "          'values': [0.3]\n",
        "        },\n",
        "    'cell_type': {\n",
        "          'values': ['lstm']\n",
        "        }\n",
        "    }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"CS6910 Assignment 3\")\n",
        "\n",
        "\n",
        "def train_sweep(config=None):\n",
        "  with wandb.init(config=config) as run:\n",
        "    config = wandb.config\n",
        "\n",
        "    input_dim = len(input_dict)\n",
        "    output_dim = len(target_dict)\n",
        "    batch_size = 32\n",
        "    val_batch_size = 32\n",
        "    enc_embedding = config.enc_embedding\n",
        "    dec_embedding = config.dec_embedding\n",
        "    hidden = config.hidden_size\n",
        "    enc_num_layers = config.enc_layers\n",
        "    dec_num_layers = config.dec_layers\n",
        "    enc_dropout = config.dropout\n",
        "    dec_dropout = config.dropout\n",
        "    max_length = max_target_length\n",
        "    cell_type = config.cell_type\n",
        "\n",
        "\n",
        "    \n",
        "    enc = EncoderRNN(device, cell_type, input_dim, enc_embedding, hidden, enc_num_layers, bidirectional = config.bidirectional, dropout_p = enc_dropout)\n",
        "    dec = DecoderRNN(device, cell_type, output_dim, dec_embedding, hidden, max_length,  dec_dropout, dec_num_layers , bidirectional = config.bidirectional)\n",
        "    model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "\n",
        "    \n",
        "    exp_name = str(config.cell_type) +'_e_'+ str(config.epochs)+'_hl_'+str(config.hidden_size)\n",
        "    exp_name = exp_name + '_enc_'+ str(config.enc_embedding) + '_dec_'+ str(config.dec_embedding)+'_el_'+ str(config.enc_layers) + '_dl_'+ str(config.dec_layers)\n",
        "    exp_name = exp_name+'_d_'+ str(config.dropout)+'_tf_'+ str(config.teacher_forcing_ratio)+'_optim_'+ config.optimiser\n",
        "    \n",
        "    wandb.run.name = exp_name\n",
        "    if (config.optimiser == 'adam'):\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "    elif (config.optimiser == 'nadam'):\n",
        "      optimizer = torch.optim.NAdam(model.parameters(), lr = 0.001)\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    trainIters(model, pairs, 32, config.epochs, optimizer, config.teacher_forcing_ratio)\n",
        "\n",
        "wandb.agent(sweep_id, train_sweep, count= 50)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "hlQ8__dMfy2I",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4- Model Inference on Test Data"
      ],
      "metadata": {
        "id": "TJdFDMDtdvC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the outputs in CSV files\n",
        "\n",
        "#Create a CSV File"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-20T08:10:17.426136Z",
          "iopub.execute_input": "2023-05-20T08:10:17.430205Z",
          "iopub.status.idle": "2023-05-20T08:10:17.435382Z",
          "shell.execute_reply.started": "2023-05-20T08:10:17.430162Z",
          "shell.execute_reply": "2023-05-20T08:10:17.433641Z"
        },
        "trusted": true,
        "id": "Pb-wQanNdvC3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def append_strings_to_csv(file_path, string1, string2, string3):\n",
        "    with open(file_path, 'a', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([string1, string2, string3])\n",
        "\n",
        "\n",
        "input_dim = len(input_dict)\n",
        "output_dim = len(target_dict)\n",
        "batch_size = 32\n",
        "val_batch_size = 32\n",
        "enc_embedding = 128\n",
        "dec_embedding = 256\n",
        "hidden = 512\n",
        "epochs = 5\n",
        "enc_num_layers = 3\n",
        "dec_num_layers = 1\n",
        "enc_dropout = 0.4\n",
        "dec_dropout = 0.4\n",
        "max_length = max_target_length\n",
        "cell_type = 'lstm'\n",
        "teacher_forcing_ratio = 0.7\n",
        "\n",
        "enc = EncoderRNN(device, cell_type, input_dim, enc_embedding, hidden, enc_num_layers, bidirectional = True, dropout_p = enc_dropout)\n",
        "dec = DecoderRNN(device, cell_type, output_dim, dec_embedding, hidden, max_length,  dec_dropout, dec_num_layers , bidirectional = True)\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "optimizer = torch.optim.NAdam(model.parameters(), lr = 0.001)\n",
        "wandb.init() \n",
        "trainIters(model, pairs, 32, epochs, optimizer, teacher_forcing_ratio)\n",
        "test_pairs = pairs[2]\n",
        "test_word_count = 0\n",
        "\n",
        "count = 1\n",
        "name = 'VanillaPredictions'+ str(count)\n",
        "file_path = '/content/drive/MyDrive/aksharantar_sampled/mar'+name+'.csv'\n",
        "\n",
        "for i in np.arange(start=0, stop=len(test_pairs)-batch_size, step=batch_size):\n",
        "    if (i + batch_size > len(test_pairs)):\n",
        "      batch_size = len(test_pairs) - i + 1  \n",
        "    test_input_tensor = []\n",
        "    test_target_tensor = []\n",
        "    for j in range(batch_size):\n",
        "        test_input_tensor.append(test_pairs[i+j][0])\n",
        "        test_target_tensor.append(test_pairs[i+j][1])\n",
        "\n",
        "    test_input_tensor = torch.stack(test_input_tensor).squeeze(1).long().cuda()\n",
        "    test_target_tensor = torch.stack(test_target_tensor).squeeze(1).long().cuda()\n",
        "\n",
        "    test_out = model.inference(test_input_tensor, test_target_tensor)\n",
        "    test_out = test_out.permute(0,2,1)\n",
        "    test_loss = criterion(test_out, test_target_tensor)\n",
        "    for j in range(batch_size):\n",
        "        input_str = print_keys_for_values(input_dict, test_input_tensor[j])\n",
        "        output_str = print_keys_for_values(target_dict, torch.argmax(test_out[j], dim = 0))\n",
        "        target_str = print_keys_for_values(target_dict, test_target_tensor[j])\n",
        "        append_strings_to_csv(file_path, input_str, target_str, output_str)\n",
        "    \n",
        "    # print(torch.argmax(val_out, dim = 1))\n",
        "    # print(val_target_tensor)\n",
        "\n",
        "\n",
        "    # val_accuracy_char = char_level_accuracy(val_target_tensor, val_out)\n",
        "    test_accuracy_word = word_level_accuracy(test_target_tensor, test_out)\n",
        "    # char_count = char_count + (val_accuracy_char)*batch_size*val_target_tensor.shape[1]\n",
        "    test_word_count = test_word_count + (test_accuracy_word)*batch_size\n",
        "    # print(word_count)\n",
        "\n",
        "\n",
        "    # char_accuracy = char_count/((len(val_pairs)-batch_size)*(val_target_tensor.shape[1]))\n",
        "test_word_accuracy = test_word_count/(len(test_pairs)-batch_size)\n",
        "print(f\"Accuracy on Test Set is {test_word_accuracy}\")"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "2tf2t-ItdvC3",
        "outputId": "9d93c919-9591-4126-e19a-a0be3ab9c0f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33med22s009\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230521_041439-ss946qdt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ed22s009/uncategorized/runs/ss946qdt' target=\"_blank\">woven-water-13</a></strong> to <a href='https://wandb.ai/ed22s009/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ed22s009/uncategorized' target=\"_blank\">https://wandb.ai/ed22s009/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ed22s009/uncategorized/runs/ss946qdt' target=\"_blank\">https://wandb.ai/ed22s009/uncategorized/runs/ss946qdt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0m 45s (- 3m 0s) (1 20%) 1.2136360\n",
            "1m 30s (- 2m 16s) (2 40%) 0.5399751\n",
            "2m 17s (- 3m 26s) (2 40%) 0.4409500\n",
            "3m 3s (- 2m 2s) (3 60%) 0.3882241\n",
            "3m 49s (- 2m 33s) (3 60%) 0.3674425\n",
            "4m 36s (- 1m 9s) (4 80%) 0.6078833\n",
            "5m 22s (- 1m 20s) (4 80%) 0.5704553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5 - Seq2Seq with Attention"
      ],
      "metadata": {
        "id": "ioQhQabLyp4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attention Decoder"
      ],
      "metadata": {
        "id": "fAswLBk6y5ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDecoderRNN(nn.Module):\n",
        "    def __init__(self, device, cell_type, output_vocab, embed_size, hidden_size, max_length, dropout_p=0.1, num_layers = 1, bidirectional = False):\n",
        "        super(AttentionDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_vocab\n",
        "        self.embed_size = embed_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.cell_type = cell_type \n",
        "        self.max_length = max_length\n",
        "        self.device = device\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding_decoder = nn.Embedding(self.output_size, self.embed_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "\n",
        "        if (cell_type == 'lstm'):\n",
        "          self.rnn = nn.LSTM( self.embed_size + hidden_size*(1+int(self.bidirectional)), hidden_size, num_layers = self.num_layers, batch_first=True, bidirectional=self.bidirectional, dropout = self.dropout_p)\n",
        "        elif (cell_type == 'gru'):\n",
        "          self.rnn = nn.GRU(self.embed_size+ hidden_size*(1+int(self.bidirectional)), hidden_size, num_layers = self.num_layers, batch_first=True, bidirectional=self.bidirectional, dropout = self.dropout_p)\n",
        "        elif (cell_type == 'rnn'):\n",
        "          self.rnn = nn.RNN(self.embed_size+ hidden_size*(1+int(self.bidirectional)), hidden_size, num_layers = self.num_layers, batch_first=True, bidirectional=self.bidirectional, dropout = self.dropout_p)\n",
        "\n",
        "\n",
        "        self.energy = nn.Linear(hidden_size*(2+int(self.bidirectional)),hidden_size)\n",
        "        self.value = nn.Linear(hidden_size,1, bias = False)\n",
        "        self.softmax = nn.Softmax(dim = 0)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "        \n",
        "        self.out = nn.Linear((1+int(self.bidirectional))*self.hidden_size, self.output_size)\n",
        "        self.out_activation = nn.LogSoftmax(dim=-1)\n",
        "  \n",
        "        self.hidden_reshape_linear = nn.Linear(hidden_size*2,hidden_size)\n",
        "\n",
        "\n",
        "    def forward(self, input, encoder_states, hidden, cell):\n",
        "        input = input.unsqueeze(1)\n",
        "        embedded_decoder = self.embedding_decoder(input)\n",
        "        embedded_decoder = self.dropout(embedded_decoder)\n",
        "\n",
        "        encoder_states = encoder_states.permute(1,0,2)\n",
        "        sequence_length = encoder_states.shape[0]\n",
        "        if self.bidirectional == True:\n",
        "          hidden_1 = self.relu(self.hidden_reshape_linear(hidden[0:2].permute(1,0,2).reshape(hidden.shape[1],-1))).unsqueeze(0)\n",
        "        else:\n",
        "          hidden_1 = hidden[0]\n",
        "\n",
        "          \n",
        "        hidden_reshaped = hidden_1.repeat(sequence_length,1,1)\n",
        "\n",
        "        energy = self.value(self.tanh(self.energy(torch.cat((hidden_reshaped,encoder_states),dim=2))))\n",
        "        attention = self.softmax(energy)\n",
        "        attention = attention.permute(1,2,0)\n",
        "        encoder_states = encoder_states.permute(1,0,2)\n",
        "        context_vector = torch.bmm(attention, encoder_states)\n",
        "\n",
        "        rnn_input = torch.cat((context_vector,embedded_decoder), dim = 2)\n",
        "      \n",
        "        \n",
        "        if (self.cell_type == 'lstm'):\n",
        "          decoder_output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
        "        elif (self.cell_type == 'gru'):\n",
        "          decoder_output, hidden = self.rnn(rnn_input, hidden)\n",
        "        elif (self.cell_type == 'rnn'):\n",
        "          decoder_output,hidden = self.rnn(rnn_input, hidden)\n",
        "\n",
        "        output = F.relu(self.out(decoder_output))\n",
        "        output = F.log_softmax(output,dim=-1)\n",
        "\n",
        "        return output, hidden, cell, attention\n",
        "\n",
        "    def init_hidden(self, encoder_hidden, encoder_cell, encoder_bidirectional):\n",
        "        hidden = encoder_hidden[-(1+int(encoder_bidirectional)): ].repeat(self.num_layers,1,1)\n",
        "        cell = encoder_cell[-(1+int(encoder_bidirectional)): ].repeat(self.num_layers,1,1)\n",
        "        return hidden, cell"
      ],
      "metadata": {
        "id": "VobL42C0y3h3",
        "execution": {
          "iopub.status.busy": "2023-05-20T19:16:13.015499Z",
          "iopub.execute_input": "2023-05-20T19:16:13.015940Z",
          "iopub.status.idle": "2023-05-20T19:16:13.051509Z",
          "shell.execute_reply.started": "2023-05-20T19:16:13.015902Z",
          "shell.execute_reply": "2023-05-20T19:16:13.050040Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionSeq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        self.max_target_length = 0\n",
        "        self.sos = 0\n",
        "               \n",
        "    def forward(self, source, target, teacher_forcing_ratio = 0.5):\n",
        "      \n",
        "        batch_size = target.shape[0]\n",
        "        target_len = target.shape[1]\n",
        "        self.max_target_length = target_len\n",
        "        target_vocab_size = self.decoder.output_size\n",
        "        \n",
        "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_hidden, encoder_cell = self.encoder.init_hidden(batch_size)\n",
        "\n",
        "        \n",
        "        if (self.encoder.cell_type == 'lstm'):\n",
        "          encoder_outputs, encoder_hidden, encoder_cell = self.encoder.forward(source, encoder_hidden, encoder_cell)\n",
        "        if (self.encoder.cell_type == 'rnn'):\n",
        "          encoder_outputs, encoder_hidden = self.encoder.forward(source, encoder_hidden, encoder_cell)\n",
        "        if (self.encoder.cell_type == 'gru'):\n",
        "          encoder_outputs, encoder_hidden = self.encoder.forward(source, encoder_hidden, encoder_cell)\n",
        "           \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = target[:,0]\n",
        "        self.sos = target[:,0]\n",
        "        hidden,cell = self.decoder.init_hidden(encoder_hidden, encoder_cell, self.encoder.bidirectional)\n",
        "        \n",
        "        for t in range(1, target_len):\n",
        "            output, hidden, cell,_ = self.decoder.forward(input, encoder_outputs, hidden, cell)\n",
        "            outputs[:,t] = output.squeeze(1)\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(-1)\n",
        "            input = target[:,t] if teacher_force else top1.squeeze(1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def inference(self, source, target):\n",
        "      \n",
        "        batch_size = source.shape[0]\n",
        "        target_len = self.max_target_length\n",
        "        target_vocab_size = self.decoder.output_size\n",
        "        \n",
        "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_hidden, encoder_cell = self.encoder.init_hidden(batch_size)\n",
        "\n",
        "        \n",
        "        if (self.encoder.cell_type == 'lstm'):\n",
        "          encoder_outputs, encoder_hidden, encoder_cell = self.encoder.forward(source, encoder_hidden, encoder_cell)\n",
        "        if (self.encoder.cell_type == 'rnn'):\n",
        "          encoder_outputs, encoder_hidden = self.encoder.forward(source, encoder_hidden, encoder_cell)\n",
        "        if (self.encoder.cell_type == 'gru'):\n",
        "          encoder_outputs, encoder_hidden = self.encoder.forward(source, encoder_hidden, encoder_cell)\n",
        "           \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = self.sos\n",
        "        input_len = encoder_outputs.shape[1]\n",
        "        hidden,cell = self.decoder.init_hidden(encoder_hidden, encoder_cell, self.encoder.bidirectional)\n",
        "        attention_map = torch.zeros(batch_size,target_len,input_len)\n",
        "        \n",
        "        for t in range(1, target_len):\n",
        "            output, hidden, cell, attention = self.decoder.forward(input,encoder_outputs, hidden, cell)\n",
        "            attention_map[:,t-1,:] = attention.squeeze(1)\n",
        "            outputs[:,t] = output.squeeze(1)\n",
        "            top1 = output.argmax(-1)\n",
        "            input = top1.squeeze(1)\n",
        "        \n",
        "#         attention_map = torch.cat(attention_map_list, dim=1)\n",
        "        # print(f\"Outputs = {outputs[:,0]}\")\n",
        "        # print(f\"Targets = {target[:,0]}\")\n",
        "        \n",
        "        return outputs, attention_map"
      ],
      "metadata": {
        "id": "JinZtTpR4q52",
        "execution": {
          "iopub.status.busy": "2023-05-20T19:16:17.317445Z",
          "iopub.execute_input": "2023-05-20T19:16:17.317829Z",
          "iopub.status.idle": "2023-05-20T19:16:17.344590Z",
          "shell.execute_reply.started": "2023-05-20T19:16:17.317795Z",
          "shell.execute_reply": "2023-05-20T19:16:17.342729Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = len(input_dict)\n",
        "output_dim = len(target_dict)\n",
        "batch_size = 32\n",
        "val_batch_size = 32\n",
        "enc_embedding = 128\n",
        "dec_embedding = 256\n",
        "hidden = 512\n",
        "enc_num_layers = 2\n",
        "dec_num_layers = 2\n",
        "enc_dropout = 0.4\n",
        "dec_dropout = 0.4\n",
        "max_length = max_target_length\n",
        "cell_type = 'lstm'\n",
        "teacher_forcing_ratio = 0.7\n",
        "\n",
        "    \n",
        "enc = EncoderRNN(device, cell_type, input_dim, enc_embedding, hidden, enc_num_layers, bidirectional = True, dropout_p = enc_dropout)\n",
        "dec = AttentionDecoderRNN(device, cell_type, output_dim, dec_embedding, hidden, max_length,  dec_dropout, dec_num_layers , bidirectional = True)\n",
        "model = AttentionSeq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "optimizer = torch.optim.NAdam(model.parameters(), lr = 0.001)\n",
        "criterion = nn.NLLLoss()\n",
        "wandb.init(project=\"CS6910 Assignment 3-Attention\")\n",
        "trainIters(model, pairs, 32, 6, optimizer, teacher_forcing_ratio, Attention = True)"
      ],
      "metadata": {
        "id": "dImmn7d3hIEN",
        "execution": {
          "iopub.status.busy": "2023-05-20T20:57:23.693576Z",
          "iopub.execute_input": "2023-05-20T20:57:23.694457Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WandB Sweep (without Attention)"
      ],
      "metadata": {
        "id": "83sqEENxdvC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'name' : 'Hyperparameter Tuning with Attention-Bayesian'\n",
        "}\n",
        "\n",
        "metric = {\n",
        "    'name': 'Val_Accuracy',\n",
        "    'goal': 'maximize'   \n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric\n",
        "\n",
        "\n",
        "parameters_dict = {\n",
        "    'optimiser': {\n",
        "        'values': ['adam']\n",
        "        },\n",
        "    'teacher_forcing_ratio':{\n",
        "         'values':[0.5,0.7]\n",
        "        },\n",
        "    'bidirectional':{\n",
        "         'values':[True, False]\n",
        "        },\n",
        "    'enc_embedding': {\n",
        "        'values': [128,256]\n",
        "        },\n",
        "    'dec_embedding': {\n",
        "        'values': [128,256]\n",
        "        },\n",
        "    'epochs': {\n",
        "          'values': [3,5]\n",
        "        },\n",
        "    'hidden_size': {\n",
        "          'values': [512]\n",
        "        },\n",
        "    'enc_layers': {\n",
        "          'values': [2,3]\n",
        "        },\n",
        "    'dec_layers': {\n",
        "          'values': [2,3]\n",
        "        },\n",
        "    'dropout': {\n",
        "          'values': [0.25,0.4]\n",
        "        },\n",
        "    'cell_type': {\n",
        "          'values': ['gru','lstm']\n",
        "        }\n",
        "    }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"CS6910 Assignment 3\")\n",
        "\n",
        "\n",
        "def train_sweep(config=None):\n",
        "  with wandb.init(config=config) as run:\n",
        "    config = wandb.config\n",
        "\n",
        "    input_dim = len(input_dict)\n",
        "    output_dim = len(target_dict)\n",
        "    batch_size = 32\n",
        "    val_batch_size = 32\n",
        "    enc_embedding = config.enc_embedding\n",
        "    dec_embedding = config.dec_embedding\n",
        "    hidden = config.hidden_size\n",
        "    enc_num_layers = config.enc_layers\n",
        "    dec_num_layers = config.dec_layers\n",
        "    enc_dropout = config.dropout\n",
        "    dec_dropout = config.dropout\n",
        "    max_length = max_target_length\n",
        "    cell_type = config.cell_type\n",
        "\n",
        "\n",
        "    \n",
        "    enc = EncoderRNN(device, cell_type, input_dim, enc_embedding, hidden, enc_num_layers, bidirectional = config.bidirectional, dropout_p = enc_dropout)\n",
        "    dec = AttentionDecoderRNN(device, cell_type, output_dim, dec_embedding, hidden, max_length,  dec_dropout, dec_num_layers , bidirectional = config.bidirectional)\n",
        "    model = AttentionSeq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "    if (config.bidirectional == True):\n",
        "        m = '_bi_'\n",
        "    else:\n",
        "        m = '_uni_'\n",
        "    \n",
        "    exp_name = str(config.cell_type) + m +'e_'+ str(config.epochs)+'_hl_'+str(config.hidden_size)\n",
        "    exp_name = exp_name + '_enc_'+ str(config.enc_embedding) + '_dec_'+ str(config.dec_embedding)+'_el_'+ str(config.enc_layers) + '_dl_'+ str(config.dec_layers)\n",
        "    exp_name = exp_name+'_d_'+ str(config.dropout)+'_tf_'+ str(config.teacher_forcing_ratio)+'_optim_'+ config.optimiser\n",
        "    \n",
        "    wandb.run.name = exp_name\n",
        "    if (config.optimiser == 'adam'):\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "    elif (config.optimiser == 'nadam'):\n",
        "      optimizer = torch.optim.NAdam(model.parameters(), lr = 0.001)\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    trainIters(model, pairs, 32, config.epochs, optimizer, config.teacher_forcing_ratio, Attention = True)\n",
        "\n",
        "wandb.agent(sweep_id, train_sweep, count= 50)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-20T15:00:10.639970Z",
          "iopub.execute_input": "2023-05-20T15:00:10.640376Z"
        },
        "trusted": true,
        "id": "rxpRADrkdvC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pairs = pairs[2]\n",
        "test_word_count = 0\n",
        "\n",
        "count = 1\n",
        "name = 'Seq2SeqAttentionPredictions'+ str(count)\n",
        "file_path = '/kaggle/working/'+name+'.csv'\n",
        "\n",
        "for i in np.arange(start=0, stop=len(test_pairs)-batch_size, step=batch_size):\n",
        "    if (i + batch_size > len(test_pairs)):\n",
        "      batch_size = len(test_pairs) - i + 1  \n",
        "    test_input_tensor = []\n",
        "    test_target_tensor = []\n",
        "    for j in range(batch_size):\n",
        "        test_input_tensor.append(test_pairs[i+j][0])\n",
        "        test_target_tensor.append(test_pairs[i+j][1])\n",
        "\n",
        "    test_input_tensor = torch.stack(test_input_tensor).squeeze(1).long().cuda()\n",
        "    test_target_tensor = torch.stack(test_target_tensor).squeeze(1).long().cuda()\n",
        "\n",
        "    test_out, attention_map = model.inference(test_input_tensor, test_target_tensor)\n",
        "    test_out = torch.permute(test_out,[0,2,1])\n",
        "    test_loss = criterion(test_out, test_target_tensor)\n",
        "    for j in range(batch_size):\n",
        "        input_str = print_keys_for_values(input_dict, test_input_tensor[j])\n",
        "        output_str = print_keys_for_values(target_dict, torch.argmax(test_out[j], dim = 0))\n",
        "        target_str = print_keys_for_values(target_dict, test_target_tensor[j])\n",
        "        append_strings_to_csv(file_path, input_str, target_str, output_str)\n",
        "    \n",
        "    # print(torch.argmax(val_out, dim = 1))\n",
        "    # print(val_target_tensor)\n",
        "\n",
        "\n",
        "    # val_accuracy_char = char_level_accuracy(val_target_tensor, val_out)\n",
        "    test_accuracy_word = word_level_accuracy(test_target_tensor, test_out)\n",
        "    # char_count = char_count + (val_accuracy_char)*batch_size*val_target_tensor.shape[1]\n",
        "    test_word_count = test_word_count + (test_accuracy_word)*batch_size\n",
        "    # print(word_count)\n",
        "\n",
        "\n",
        "    # char_accuracy = char_count/((len(val_pairs)-batch_size)*(val_target_tensor.shape[1]))\n",
        "test_word_accuracy = test_word_count/(len(test_pairs)-batch_size)\n",
        "print(f\"Accuracy on Test Set is {test_word_accuracy}\")\n",
        "# print(attention_map.shape)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "M7X1Cd3fdvC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.imshow(attention_map[31].detach().numpy())"
      ],
      "metadata": {
        "trusted": true,
        "id": "4t3ro6RkdvC5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}